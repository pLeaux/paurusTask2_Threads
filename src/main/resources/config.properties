# mySQL connection
dbDriver=com.mysql.cj.jdbc.Driver
dbConnection=jdbc:mysql://localhost:3306/paurustask2?useSSL=false&serverTimezone=UTC
dbUserName=
dbPassword=
dbCreateTableSql=create table foo_random (id int not null primary key auto_increment,  fileRowNo integer, match_id varchar(32), market_id int, outcome_id varchar(255), specifiers varchar(255), date_insert datetime not null default now()) 
dbDropTableSql=drop table if exists foo_random

# source file location (warning: use / or \\ delimiter instead of \)
srcFilePath=c:/temp/foo_random.txt

# number of SQL insert statements, sent to Database in one step (usage in DbWriter class); can be adjusted to optimize speed; default is 1000
# batch with 10000 records needs 30 seconds to process on my PC, 1000 records 3 seconds ... so, for local connection, it looks like there is no gain for larger batch
dbInsertBatchCount=1000

# Number of database threads, that will be started. each thread opens its own database connection. Default is 20, and 50 seems to be limit for my mySQL.
# Using multiple connections speeds-up the import significantly in my configuration (SSD disc + 16GB RAM), but is probably dependent of mySQL settings 
dbDbWriterThreadCount=20

# for debugging, Sleep for fileSleepMicrosecondsPerRecord (as min. "Sleep()" time is 1 millisecond, sleep is executed for "fileSleepMicrosecondsPerRecord" for each 1000 records)
# set to 0 for "production" speed, default for debug is 1000; this setting has little impact on total time, because it is determined by DbWriterThread
fileThread_SleepMicroseconds_AfterEach1000Records=100

# console output spoils speed, but is essential for checking, how FileReaderThread and DbWriterThread execute simultaneously
# set consoleLog_showDebugInfo=0 to log only starting and finishing time of FileReaderThread and DbWriterThread
consoleLog_showDebugInfo=1

